==============================================================================
Ini files
['sh', '-c', 'for i in "$@"; do echo "file: $i"; cat "$i"; done', '--', '/opt/couchbase/etc/couchdb/default.ini', '/opt/couchbase/etc/couchdb/default.d/capi.ini', '/opt/couchbase/etc/couchdb/default.d/geocouch.ini', '/opt/couchbase/etc/couchdb/local.ini']
==============================================================================
file: /opt/couchbase/etc/couchdb/default.ini
; 

; Upgrading CouchDB will overwrite this file.

[couchdb]
database_dir = /opt/couchbase/var/lib/couchdb
view_index_dir = /opt/couchbase/var/lib/couchdb
util_driver_dir = /opt/couchbase/lib/couchdb/erlang/lib/couch-1.2.0a-961ad59-git/priv/lib
delayed_commits = true ; set this to false to ensure an fsync before 201 Created is returned
uri_file = /opt/couchbase/var/run/couchdb/couch.uri
; Maximum number of distinct view update/building processes at any point in time.
max_parallel_indexers = 4
max_parallel_replica_indexers = 2
max_parallel_spatial_indexers = 4
consistency_check_precompacted = false
consistency_check_compacted = false
; Maximum period for which we attempt to retry file operations on Windows.
windows_file_op_retry_period = 5000

[database_compaction]
; larger buffer sizes can originate smaller files
doc_buffer_size = 524288 ; value in bytes
checkpoint_after = 5242880 ; checkpoint after every N bytes were written

[httpd]
port = 5984
bind_address = 127.0.0.1
authentication_handlers =
; authentication_handlers = {couch_httpd_oauth, oauth_authentication_handler}, {couch_httpd_auth, cookie_authentication_handler}, {couch_httpd_auth, default_authentication_handler}
default_handler = {couch_httpd_db, handle_request}
allow_jsonp = false
db_frontend = couch_db_frontend
; Options for the MochiWeb HTTP server.
;server_options = [{backlog, 128}, {acceptor_pool_size, 16}]
; For more socket options, consult Erlang's module 'inet' man page.
;socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]

[ssl]
port = 6984

[log]
file = /opt/couchbase/var/log/couchdb/couch.log
level = info
include_sasl = true

[couch_httpd_auth]
authentication_db = _users
authentication_redirect = /_utils/session.html
require_valid_user = false
timeout = 600 ; number of seconds before automatic logout
auth_cache_size = 50 ; size is number of cache entries

[daemons]
view_manager={couch_view, start_link, []}
set_view_manager={couch_set_view, start_link, [prod, mapreduce_view]}
set_view_manager_dev={couch_set_view, start_link, [dev, mapreduce_view]}
index_merger_pool={lhttpc_manager, start_link, [[{connection_timeout, 90000}, {pool_size, 10000}, {name, couch_index_merger_connection_pool}]]}
query_servers={couch_query_servers, start_link, []}
httpd={couch_httpd, start_link, []}
uuids={couch_uuids, start, []}
auth_cache={couch_auth_cache, start_link, []}
couch_set_view_ddoc_cache={couch_set_view_ddoc_cache, start_link, []}
replication_manager={couch_replication_manager, start_link, []}
compaction_daemon={couch_compaction_daemon, start_link, []}

[httpd_global_handlers]
/ = {couch_httpd_misc_handlers, handle_welcome_req, <<"Welcome">>}
_active_tasks = {couch_httpd_misc_handlers, handle_task_status_req}
_view_merge = {couch_httpd_view_merger, handle_req}
_set_view = {couch_set_view_http, handle_req}

[httpd_db_handlers]
_view_cleanup = {couch_httpd_db, handle_view_cleanup_req}
_compact = {couch_httpd_db, handle_compact_req}
_design = {couch_httpd_db, handle_design_req}
_changes = {couch_httpd_db, handle_changes_req}

[httpd_design_handlers]
_view = {couch_httpd_view, handle_view_req}
_info = {couch_httpd_db,   handle_design_info_req}

[uuids]
; Known algorithms:
;   random - 128 bits of random awesome
;     All awesome, all the time.
;   sequential - monotonically increasing ids with random increments
;     First 26 hex characters are random. Last 6 increment in
;     random amounts until an overflow occurs. On overflow, the
;     random prefix is regenerated and the process starts over.
;   utc_random - Time since Jan 1, 1970 UTC with microseconds
;     First 14 characters are the time in hex. Last 18 are random.
algorithm = sequential

[replicator]
db = _replicator
; Maximum replicaton retry count can be a non-negative integer or "infinity".
max_replication_retry_count = 10
; More worker processes can give higher network throughput but can also
; imply more disk and network IO.
worker_processes = 4
; With lower batch sizes checkpoints are done more frequently. Lower batch sizes
; also reduce the total amount of used RAM memory.
worker_batch_size = 500
; Maximum number of HTTP connections per replication.
http_connections = 20
; HTTP connection timeout per replication.
; Even for very fast/reliable networks it might need to be increased if a remote
; database is too busy.
connection_timeout = 30000
; If a request fails, the replicator will retry it up to N times.
retries_per_request = 2
; Some socket options that might boost performance in some scenarios:
;       {nodelay, boolean()}
;       {sndbuf, integer()}
;       {recbuf, integer()}
;       {priority, integer()}
; See the `inet` Erlang module's man page for the full list of options.
socket_options = [{keepalive, true}, {nodelay, false}]
; set to true to validate peer certificates
verify_ssl_certificates = false
; file containing a list of peer trusted certificates (PEM format)
; ssl_trusted_certificates_file = /etc/ssl/certs/ca-certificates.crt
; maximum peer certificate depth (must be set even if certificate validation is off)
ssl_certificate_max_depth = 3

[compaction_daemon]
; The delay, in seconds, between each check for which database and view indexes
; need to be compacted.
check_interval = 60
; If a database or view index file is smaller then this value (in bytes),
; compaction will not happen. Very small files always have a very high
; fragmentation therefore it's not worth to compact them.
min_file_size = 131072

[compactions]
; List of compaction rules for the compaction daemon.
; The daemon compacts databases and their respective view groups when all the
; condition parameters are satisfied. Configuration can be per database or
; global, and it has the following format:
;
; database_name = [ {ParamName, ParamValue}, {ParamName, ParamValue}, ... ]
; _default = [ {ParamName, ParamValue}, {ParamName, ParamValue}, ... ]
;
; Possible parameters:
;
; * db_fragmentation - If the ratio (as an integer percentage), of the amount
;                      of old data (and its supporting metadata) over the database
;                      file size is equal to or greater then this value, this
;                      database compaction condition is satisfied.
;                      This value is computed as:
;
;                           (file_size - data_size) / file_size * 100
;
;                      The data_size and file_size values can be obtained when
;                      querying a database's information URI (GET /dbname/).
;
; * view_fragmentation - If the ratio (as an integer percentage), of the amount
;                        of old data (and its supporting metadata) over the view
;                        index (view group) file size is equal to or greater then
;                        this value, then this view index compaction condition is
;                        satisfied. This value is computed as:
;
;                            (file_size - data_size) / file_size * 100
;
;                        The data_size and file_size values can be obtained when
;                        querying a view group's information URI
;                        (GET /dbname/_design/groupname/_info).
;
; * from _and_ to - The period for which a database (and its view groups) compaction
;                   is allowed. The value for these parameters must obey the format:
;
;                   HH:MM - HH:MM  (HH in [0..23], MM in [0..59])
;
; * strict_window - If a compaction is still running after the end of the allowed
;                   period, it will be canceled if this parameter is set to 'true'.
;                   It defaults to 'false' and it's meaningful only if the *period*
;                   parameter is also specified.
;
; * parallel_view_compaction - If set to 'true', the database and its views are
;                              compacted in parallel. This is only useful on
;                              certain setups, like for example when the database
;                              and view index directories point to different
;                              disks. It defaults to 'false'.
;
; Before a compaction is triggered, an estimation of how much free disk space is
; needed is computed. This estimation corresponds to 2 times the data size of
; the database or view index. When there's not enough free disk space to compact
; a particular database or view index, a warning message is logged.
;
; Examples:
;
; 1) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}]
;    The `foo` database is compacted if its fragmentation is 70% or more.
;    Any view index of this database is compacted only if its fragmentation
;    is 60% or more.
;
; 2) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}]
;    Similar to the preceding example but a compaction (database or view index)
;    is only triggered if the current time is between midnight and 4 AM.
;
; 3) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}, {strict_window, true}]
;    Similar to the preceding example - a compaction (database or view index)
;    is only triggered if the current time is between midnight and 4 AM. If at
;    4 AM the database or one of its views is still compacting, the compaction
;    process will be canceled.
;
; 4) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}, {strict_window, true}, {parallel_view_compaction, true}]
;    Similar to the preceding example, but a database and its views can be
;    compacted in parallel.
;
;_default = [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "23:00"}, {to, "04:00"}]
;
;[vendor]
;name = Couchbase Single Server
;version = 2.0.0
;url = http://www.couchbase.com/

[mapreduce]
; Maximum duration, in milliseconds, for the execution time of all the map/reduce
; functions in a design document against a single document (map function) or against
; a list of map values/reductions (reduce/rereduce function).
function_timeout = 10000
; The maximum byte size allowed to be emitted for a single document. This is the
; sum of the sizes of all emitted keys and values. A maximum of 0 means no limit.
max_kv_size_per_doc = 1048576

[set_views]
ddoc_cache_size = 1048576
btree_kv_node_threshold = 7168
btree_kp_node_threshold = 6144
; For incremental updates (value in bytes).
indexer_max_insert_batch_size = 1048576
; Maximum size (in bytes) of documents sent to the JavaScript engine.
; A value of 0 means no limit, any document is passed to the engine.
indexer_max_doc_size = 20971520
; Sleep period for updates to wait when compactor is in retry phase.
; Value is in milliseconds.
throttle_period = 0

[spatial_views]
vtree_kv_node_threshold = 2000
vtree_kp_node_threshold = 2000
vtree_min_fill_rate = 0.4

[dcp]
port = 11209
connection_timeout = 5000
flow_control_buffer_size = 20971520
file: /opt/couchbase/etc/couchdb/default.d/capi.ini
[couchdb]
max_dbs_open = 10000
database_dir = /opt/couchbase/var/lib/couchbase/data
view_index_dir = /opt/couchbase/var/lib/couchbase/data


[httpd]
db_frontend = capi_frontend
bind_address = 0.0.0.0
port = 8092
; this gets us auth support on capi port
WWW-Authenticate = Basic realm="capi"

[httpd_db_handlers]
_all_docs = {capi_view, all_docs_db_req}

[httpd_design_handlers]
_view = {capi_view, handle_view_req}
_spatial = {capi_spatial, handle_view_req}

[database_compaction]
doc_buffer_size = 2097152
checkpoint_after = 20971520

[daemons]
; Started by ns_server's supervision trees.
compaction_daemon =
replication_manager =

; Not using these in couchbase
stats_aggregator =
stats_collector =

[compaction_daemon]
check_interval = 30
min_file_size = 131072

[httpd_global_handlers]
_pre_replicate = {capi_replication, handle_pre_replicate}
_mass_vbopaque_check = {capi_replication, handle_mass_vbopaque_check}
_commit_for_checkpoint = {capi_replication, handle_commit_for_checkpoint}
_view_merge = {capi_view, handle_view_merge_req}
_spatial_merge = {capi_spatial, handle_view_merge_req}

;[compactions]
;_default = [{db_fragmentation, {"30%", nil}},
;            {view_fragmentation, {"30%", nil}}]
;

; * db_fragmentation / view_fragmentation
;
; Both expect a tuple of {Ratio, ByteLimit} where Ratio is an integer
; percentange of old data vs all data, and the ByteLimit is the total size
; of all data - new data.
; When fragemnted data is greater than or equal to either of these values,
; auto compaction is triggered.
; both values can be nil to ignore the conditions
file: /opt/couchbase/etc/couchdb/default.d/geocouch.ini
[daemons]
spatial_view_manager={couch_set_view, start_link, [prod, spatial_view]}
spatial_view_manager_dev={couch_set_view, start_link, [dev, spatial_view]}

[httpd_global_handlers]
_spatial_view = {spatial_http, handle_req}

[spatial_views]
vtree_kv_node_threshold = 4000
vtree_kp_node_threshold = 4000
vtree_min_fill_rate = 0.4
file: /opt/couchbase/etc/couchdb/local.ini
; CouchDB Configuration Settings

; Custom settings should be made in this file. They will override settings
; in default.ini, but unlike changes made to default.ini, this file won't be
; overwritten on server upgrade.

[couchdb]
;max_document_size = 4294967296 ; bytes
database_dir = /data/db
view_index_dir = /data/db

[httpd]
;port = 5984
;bind_address = 127.0.0.1
; Options for the MochiWeb HTTP server.
;server_options = [{backlog, 128}, {acceptor_pool_size, 16}]
; For more socket options, consult Erlang's module 'inet' man page.
;socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]

; Uncomment next line to trigger basic-auth popup on unauthorized requests.
;WWW-Authenticate = Basic realm="administrator"

; Uncomment next line to set the configuration modification whitelist. Only
; whitelisted values may be changed via the /_config URLs. To allow the admin
; to change this value over HTTP, remember to include {httpd,config_whitelist}
; itself. Excluding it from the list would require editing this file to update
; the whitelist.
;config_whitelist = [{httpd,config_whitelist}, {log,level}, {etc,etc}]

[httpd_global_handlers]
;_google = {couch_httpd_proxy, handle_proxy_req, <<"http://www.google.com">>}

[couch_httpd_auth]
; If you set this to true, you should also uncomment the WWW-Authenticate line
; above. If you don't configure a WWW-Authenticate header, CouchDB will send
; Basic realm="server" in order to prevent you getting logged out.
; require_valid_user = false

[log]
;level = debug
level = info

[os_daemons]
; For any commands listed here, CouchDB will attempt to ensure that
; the process remains alive while CouchDB runs as well as shut them
; down when CouchDB exits.
;foo = /path/to/command -with args

[daemons]
; enable SSL support by uncommenting the following line and supply the PEM's below.
; the default ssl port CouchDB listens on is 6984
; httpsd = {couch_httpd, start_link, [https]}

[ssl]
;cert_file = /full/path/to/server_cert.pem
;key_file = /full/path/to/server_key.pem

; To enable Virtual Hosts in CouchDB, add a vhost = path directive. All requests to
; the Virual Host will be redirected to the path. In the example below all requests
; to http://example.com/ are redirected to /database.
; If you run CouchDB on a specific port, include the port number in the vhost:
; example.com:5984 = /database

[vhosts]
;example.com = /database/

[update_notification]
;unique notifier name=/full/path/to/exe -with "cmd line arg"

; To create an admin account uncomment the '[admins]' section below and add a
; line in the format 'username = password'. When you next start CouchDB, it
; will change the password to a hash (so that your passwords don't linger
; around in plain-text files). You can add more admin accounts with more
; 'username = password' lines. Don't forget to restart CouchDB after
; changing this.
[admins]
;admin = mysecretpassword
